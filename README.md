# MLOps Pipeline para Clasificaci√≥n de Enfermedades

**Prototipo MLOps para diagn√≥stico m√©dico con despliegue simplificado usando Docker Compose.**

---

## Requisitos Previos
- [Docker Desktop](https://www.docker.com/products/docker-desktop) instalado y en ejecuci√≥n.
- Windows/macOS/Linux con WSL2 habilitado (para Windows).

---

## Instalaci√≥n con Docker Compose

### 1. Clonar el repositorio
```bash
git clone https://github.com/Samhernesp/Docker-and-MLOps-Pipeline-.git
cd Docker-and-MLOps-Pipeline-
```

### 2. Construir y ejecutar
En el directorio del proyecto ejecutar el siguiente comando:
```bash
docker-compose up
```


### 3. Acceder a la aplicaci√≥n
Accede en un navegador a la siguiente ruta:
```bash
http://localhost:8501
```
---
## Uso

- Interfaz de Usuario:
    - Ingresa los valores num√©ricos requeridos:

        - Edad (a√±os)
          
        - G√©nero
          
        - Tipo de sangre

        - Presi√≥n arterial sist√≥lica (mm Hg)

        - Presi√≥n arterial diast√≥lica (mm Hg)

        - D√≠as de ejercicio al mes

- Resultados:
    - El sistema mostrar√° uno de estos estados con colores e iconos:

        - ‚úÖ NO ENFERMO (Verde)

        - ‚ö†Ô∏è ENFERMEDAD LEVE (Amarillo)

        - üö® ENFERMEDAD AGUDA/CR√ìNICA (Rojo)


## **Desarrollo**

### **Dise√±o**

#### **¬øQu√© restricciones y limitaciones existen?**

Del planteamiento inicial del problema, se puede identificar r√°pidamente una restricci√≥n que es la poca cantidad de datos que existen de las enfermedades hu√©rfanas, por lo tanto, es imperativo que se tomen medidas con respecto a esta situaci√≥n, ya que en el caso de entrenar un modelo con estas caracter√≠sticas va a tener una tendencia a identificar los casos de enfermedades hu√©rfanas como casos de enfermedades comunes y por consiguiente a identificarlo con una de las clases con las que pueda coincidir mas pero de los datos mas representativos. Esto significa entonces que nuestro sistema estar√≠a limitado en su mayor√≠a a enfermedades comunes y tendr√≠a un rendimiento muy bajo para casos de enfermedades hu√©rfanas.

Otra de las limitaciones que se puede identificar a profundidad en este contexto es la limitada capacidad que puede suponer metodolog√≠as y algoritmos de Machine Learning tradicional, ya que tienen una capacidad limitada frente a grandes fuentes de datos como se nos plantea en este caso. Debido a que algoritmos como SVM, Random Forest, etc, tienen limitadas escalabilidad computacional por su elevada complejidad temporal de alrededor de , y la limitada capacidad de memoria pues estos algoritmos requieren que los datos se encuentren en RAM.

De la misma manera, estos algoritmos tradicionales no est√°n dise√±ados en su mayor√≠a para trabajar con datos no estructurados, y en este caso, existe la posibilidad de que una de las caracter√≠sticas que se posea para entrenar el modelo sean textos sin procesar, que contengan todo el analisis que realiza por escrito un doctor sobre un paciente en espec√≠fico, y por tanto esto se convierta en una de las materias primas para la construcci√≥n del modelo. As√≠, no es posible trabajar con este tipo de datos si se utilizan algoritmos tradicionales de Machine Learning, o no seria lo ideal para esto.

Por √∫ltimo, y de la mano con la segunda limitaci√≥n ya comentada, en t√©rminos econ√≥micos y de eficiencia, no es correcto trabajar con algoritmos que no est√©n optimizados para trabajar con grandes cantidades de datos, es decir que no tengan la capacidad de tener un entrenamiento distribuido o paralelo. Debido a que esto derivar√≠a en altos costes de energ√≠a y almacenamiento debido a los altos requerimientos de tiempo y memoria que pueden tener los algoritmos tradicionales frente a millones de datos.

#### **¬øQu√© tipos de datos se tienen?**

En este caso vamos a partir de la suposici√≥n de que se cuenta con una base de datos que cuenta con datos estructurados, por practicidad solo se van a tener como caracter√≠sticas la edad, el g√©nero, tipo de sangre, presi√≥n arterial, cantidad de ejercicio mensual. En este caso, contar√≠amos con 5 diferentes tipos de variables, de las cuales 3 son variables num√©ricas, que son la edad, la presi√≥n arterial, y la cantidad de ejercicio mensual, y 2 son variables categ√≥ricas.

En un analisis con un poco mas de profundidad de las variables podr√≠amos darnos cuenta de varios puntos importantes, para el caso de la variable edad esta puede encontrarse entre valores de 0 a 100 aproximadamente, suponiendo que la edad se encuentra en a√±os. La presi√≥n arterial, aunque se mide num√©ricamente generalmente se valora por medio de rangos, de la siguiente manera:

![image](https://github.com/user-attachments/assets/c6181c60-ff2d-49fa-84ca-2bde2e7b5f2d)


Fuente: American Heart Association

Como podemos ver en la tabla anterior, la presi√≥n arterial se eval√∫a con dos medidas diferentes es necesario contar con ambas medidas para dar valoraciones m√°s exactas.

La caracter√≠stica del g√©nero cuenta con solamente dos categor√≠as que son masculino y femenino. El tipo de sangre cuenta con solo 4 categor√≠as, que son A, B, AB y O, por practicidad no se tendr√° en consideraci√≥n del factor Rh (Positivo - Negativo). Y por ultimo la variable cantidad de ejercicio mensual es una variable discreta, que representa el promedio de d√≠as que una persona realiza actividad f√≠sica al mes.

### **Desarrollo**

#### **¬øDe qu√© fuentes provienen los datos y c√≥mo se manejan?**

Inicialmente supondremos que los datos base del problema van a provenir de la entidad la cual est√° necesitando la construcci√≥n del modelo, en este caso vamos a suponer que es un hospital el que espera este modelo, y por tanto va a proveer informaci√≥n inicial con la cual se puede comenzar a experimentar y a definir las caracter√≠sticas de inter√©s, es importante que los datos iniciales provengan de la entidad contratante ya que si se utilizan de entrada datos externos se corre el peligro que existan caracter√≠sticas que no sean recopiladas por la entidad y que por lo tanto no son datos reales que puedan ingresar los m√©dicos a la hora de buscar predicciones del modelo.

Despues de la determinaci√≥n de las caracter√≠sticas de inter√©s, ahora si se proceder√° a extraer datos de terceros que tengan estas mismas caracter√≠sticas, pero que cuenten con clases distintas, como lo ser√≠a el caso de las enfermedades hu√©rfanas, para ayudar a balancear la cantidad de datos que enfermedades hu√©rfanas y enfermedades comunes.

Cuando ya se han recopilados los datos esperados y necesarios, es importante hacer un manejo correcto de estos, justo despu√©s de su recopilaci√≥n es esencial su almacenamiento, por lo tanto, vamos a usar una base de datos que tenga la capacidad de almacenar grandes cantidades de datos del orden de millones o miles de millones, y que a su vez se pueda consultar eficientemente los datos cuando sean requeridos para el preprocesamiento y entrenamiento.

En el preprocesamiento de los datos es necesario tener en cuenta las particularidades de las caracter√≠sticas analizadas en el dise√±o para construir un conjunto de datos que sea √∫til para la construcci√≥n de un buen modelo. Por lo tanto, para las variables num√©ricas solo es necesario asegurar el que el tipo de variable corresponda a lo que describe la misma, en este caso las variables edad y cantidad de ejercicio mensual son variables discretas y por lo tanto se utiliza un tipo de dato entero. Despues es necesario normalizar o estandarizar de acuerdo con la distribuci√≥n de los datos, no gaussiana o gaussiana respectivamente.

En este caso no se est√° teniendo en cuenta la variable presi√≥n arterial en cuenta para el procesamiento anterior ya que por su forma de analizar puede brindar m√°s informaci√≥n clasificar los rangos anteriormente mostrados como categor√≠as. De esta manera las dos variables de presi√≥n arterial se convierten en una sola variable categ√≥rica que cuenta con las clases normal, elevada, alta 1, alta 2 y crisis.

Finalmente, para las variables categ√≥ricas se realiza un √∫nico procedimiento conocido como el one-hot enconding, que convierte las categor√≠as de cada caracter√≠stica categ√≥rica en una nueva caracter√≠stica binaria. Dando como resultado una base de datos con 13 caracter√≠sticas totalmente preprocesadas y listas para entrenar un modelo.

#### **¬øQu√© tipos de modelos de ML se puede usar?**

Para elegir un modelo adecuado para nuestra situaci√≥n, lo primero que podemos resaltar es una de las limitaciones comentadas en el dise√±o, en cuanto a la gran cantidad de datos que se deben usar para entrenar un modelo y que por tanto ciertas arquitecturas o algoritmos tradicionales son descartados inicialmente. Con esto en mente, podemos filtrar los modelos por su capacidad de soportar paralelismo y computaci√≥n distribuida. Adem√°s, suponiendo que el flujo de pacientes en el hospital no es lo suficientemente grande para aportar una cantidad considerable de datos diariamente ni semanalmente para considerar reentrenar el modelo con estas temporalidades, y si tambien consideramos que requiere cierto tiempo para que se pueda confirmar si la predicci√≥n dada es real o no, podemos considerar que el modelo deber√≠a estar actualiz√°ndose mensualmente con el batch de datos de este periodo.

Con estas caracter√≠sticas definidas ya podemos empezar a pensar algunas opciones de modelos como XGBoost, MLP tradicional, LightGBM.

#### **¬øC√≥mo se van a validar/testear?**

Para validar y testear los modelos resultantes, vamos a dividir los datos desde un principio en tres datasets completamente diferentes que guarden cada uno las mismas proporciones y distribuci√≥n de las clases de enfermedad (No Enfermo, Enfermo Leve, Enfermedad Aguda, Enfermedad Cr√≥nica ) as√≠ como el tipo de enfermedad (Enfermedad Com√∫n, Enfermedad Huerfana). Esto con el fin de que cada dataset represente lo m√°s fielmente las condiciones normales de los datos.

La divisi√≥n del conjunto de datos tiene que ser una cantidad que sea estad√≠sticamente significativa, por eso se realizan las verificaciones comentadas anteriormente, pero tambien se debe tener cuidado con las distribuciones de las variables de importancia as√≠ como con medias y varianzas. En este caso al tener un gran conjunto de datos se puede empezar con una distribuci√≥n de 70, 15, 15, y posteriormente con las verificaciones dadas se puede llevar incluso a 80, 10, 10.

Con esto asegurado, se realizan las iteraciones necesarias del modelo, solo usando train y val para buscar maximizar las m√©tricas necesarias para el dataset de validaci√≥n. Y cuando ya se tengan un modelo definido como el mejor para la validaci√≥n, si se puede proceder a realizar las pruebas con el conjunto de test. Esto se realiza para evitar que a trav√©s de las iteraciones de los modelos los hiperparametros puedan ir causando un posible sobreajuste en el conjunto de test.

### **Producci√≥n**

#### **¬øC√≥mo se va a desplegar la soluci√≥n?**

La soluci√≥n se desplegar√° inicialmente en un entorno de nube escalable (ej: AWS o Azure) para garantizar acceso global y capacidad de procesamiento bajo demanda. Se integrar√° con los sistemas de historiales cl√≠nicos electr√≥nicos (EHR) del hospital mediante APIs est√°ndar como HL7 o FHIR, asegurando compatibilidad con plataformas como Epic o Cerner. Para facilitar el uso diario, se desarrollar√° una interfaz sencilla dentro del flujo de trabajo m√©dico, donde los doctores ingresen s√≠ntomas y reciban predicciones en tiempo real.

#### **¬øSe necesita alg√∫n tipo de monitoreo para esta aplicaci√≥n?**

S√≠, es cr√≠tico implementar dos tipos de monitoreo:

Rendimiento del modelo: Alertas si la precisi√≥n general o el recall de enfermedades hu√©rfanas caen por debajo de un umbral predefinido (ej: <85% en F1-score para comunes, <70% en recall para hu√©rfanas).

Calidad de datos: Detecci√≥n de valores at√≠picos o formatos incorrectos en nuevas entradas (ej: presi√≥n arterial = 300/150, g√©nero = "Otro" si no est√° permitido).

Adem√°s, se incluir√° un bot√≥n de "Retroalimentaci√≥n" para que los m√©dicos reporten predicciones err√≥neas, lo que activar√° una revisi√≥n manual.

#### **¬øPueden existir nuevos datos necesarios quiz√°s para re-entrenar el modelo?**

S√≠. Cada mes, se recolectar√°n nuevos casos confirmados (tanto comunes como hu√©rfanas) para re-entrenar el modelo. Sin embargo, dado el costo computacional, solo se re-entrenar√° completamente cada 3 meses, aplicando actualizaciones incrementales mensuales con t√©cnicas como fine-tuning en lotes peque√±os. Para enfermedades hu√©rfanas, se priorizar√° la incorporaci√≥n inmediata de nuevos casos validados, incluso fuera del ciclo regular, usando active learning para ajustar el modelo con los ejemplos m√°s informativos.

## **Diagrama del Pipeline de MLOps**

![image](https://github.com/user-attachments/assets/45e77671-ab49-46c4-a5f2-3dbbda7301df)


## **Data Input**  
La etapa de entrada de datos se centra en consolidar informaci√≥n cl√≠nica de m√∫ltiples fuentes para garantizar diversidad y representatividad. Los historiales electr√≥nicos del hospital (EHR) proporcionan datos estructurados como edad, g√©nero y presi√≥n arterial, esenciales para capturar patrones de enfermedades comunes. Para abordar la escasez de datos en enfermedades hu√©rfanas, se integran bases p√∫blicas como Orphanet y colaboraciones con centros especializados, que aportan casos raros validados cl√≠nicamente. Estos datos se almacenan en Amazon S3 o Redshift, elegidos por su capacidad para manejar grandes vol√∫menes y garantizar accesibilidad segura. La validaci√≥n de esquemas asegura que todas las fuentes compartan la misma estructura como en el caso de la presi√≥n arterial como par sist√≥lica/diast√≥lica, evitando inconsistencias que afecten el entrenamiento. Esta etapa es la base para un modelo equilibrado, pues combina datos internos , que son abundantes pero sesgados hacia enfermedades comunes, con datos externos escasos pero cr√≠ticos para rarezas, como las enfermedades huerfanas.

## **Preprocesamiento**  
El preprocesamiento transforma los datos en un formato usable para el modelo, priorizando la relevancia cl√≠nica. Las variables num√©ricas como edad y d√≠as de ejercicio mensual, se estandarizan para evitar sesgos por escalas dispares, mientras que las categ√≥ricas como g√©nero y tipo de sangre, se codifican con one-hot para preservar su naturaleza no ordinal. La presi√≥n arterial, inicialmente en valores num√©ricos, se convierte en categor√≠as cl√≠nicas normal, elevada, etc. siguiendo los est√°ndares de la American Heart Association, lo que permite al modelo interpretar rangos m√©dicamente significativos. Para enfermedades hu√©rfanas, se aplican t√©cnicas como SMOTE o GANs para generar muestras sint√©ticas, equilibrando su representaci√≥n sin alterar patrones reales. Este paso incluye tambi√©n la depuraci√≥n de anomal√≠as como la presencia de valores imposibles como 300/150 en presi√≥n arterial, asegurando que el dataset refleje solo escenarios cl√≠nicos plausibles. El resultado es un conjunto de datos homog√©neo, listo para alimentar algoritmos de ML.

## **Entrenamiento del Modelo**  
El entrenamiento utiliza un enfoque dual para abordar la disparidad de datos. Para enfermedades comunes, se implementan modelos escalables como XGBoost o LightGBM, optimizados mediante b√∫squeda de hiperpar√°metros y validaci√≥n cruzada estratificada, lo que garantiza eficiencia incluso con millones de registros. En paralelo, las redes de Few-Shot Learning como Prototypical Networks se entrenan con embeddings preprocesados de enfermedades comunes, permiti√©ndoles generalizar a partir de pocos ejemplos de enfermedades hu√©rfanas. La validaci√≥n se realiza en tres conjuntos (70%-15%-15%), con m√©tricas diferenciadas: F1-score para clases mayoritarias y Recall/AUC-PR para minoritarias, asegurando que el modelo no descarte casos raros por su escasez. Esta etapa prioriza la interoperabilidad, en donde los modelos para enfermedades comunes y hu√©rfanas se ensamblan en un pipeline √∫nico, donde las predicciones se combinan jer√°rquicamente, priorizando se√±ales de rareza, antes de entregar un diagn√≥stico integrado.

## **Despliegue del Modelo**  
El despliegue se realiza en una infraestructura h√≠brida dise√±ada para integraci√≥n cl√≠nica fluida. Los modelos se encapsulan en contenedores Docker gestionados por Kubernetes, permitiendo escalabilidad autom√°tica durante picos de demanda en hospitales. Una API REST se integra con los sistemas EHR mediante est√°ndares FHIR/HL7, facilitando predicciones en tiempo real dentro del flujo de trabajo m√©dico como para alertas autom√°ticas en historiales. Para casos sin integraci√≥n directa, una interfaz Streamlit permite a los m√©dicos ingresar datos manualmente, con validaciones en tiempo real como el bloqueo de valores fuera de rangos cl√≠nicos. La interpretabilidad se garantiza mediante reportes SHAP, que explican predicciones en t√©rminos m√©dicos para conocer las variables que m√°s influyeron en la predicci√≥n. Esta etapa prioriza la usabilidad: el modelo opera como un servicio silencioso en segundo plano para EHRs, pero est√° accesible como herramienta independiente para contextos sin automatizaci√≥n.

## **Monitoreo del Modelo**  
El monitoreo continuo asegura que el modelo se mantenga relevante ante cambios en patrones cl√≠nicos. Se implementan pruebas de drift estad√≠stico (KS-test) para detectar desplazamientos en distribuciones de datos, un ejemplo de esto fue el aumento de pacientes con presi√≥n arterial elevada post-pandemia, lo que activa alertas para revisi√≥n. Un sistema de retroalimentaci√≥n permite a los m√©dicos reportar diagn√≥sticos err√≥neos, almacenando estos casos en una base prioritaria para re-entrenamiento. Las actualizaciones siguen un ciclo dual: fine-tuning mensual con nuevos datos comunes y re-entrenamientos trimestrales que incorporan casos raros validados. Para enfermedades hu√©rfanas, el Active Learning selecciona autom√°ticamente los casos m√°s informativos que puedan contener s√≠ntomas at√≠picos, maximizando el aprendizaje con m√≠nimos datos. Los dashboards en Streamlit o Tableau visualizan m√©tricas clave como la precisi√≥n por enfermedad o la tasa de drift, proporcionando transparencia total al equipo m√©dico y de TI. Esta etapa cierra el ciclo de MLOps, transformando el modelo en un sistema adaptativo que evoluciona con la pr√°ctica cl√≠nica real.
